{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02ffa478",
   "metadata": {},
   "source": [
    "PDF MALWARE DATASET TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d584bfb",
   "metadata": {},
   "source": [
    "Importing all the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56679a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           \\t%PDF-1.3\n",
       "1           \\t%PDF-1.6\n",
       "2           \\t%PDF-1.3\n",
       "3           \\t%PDF-1.3\n",
       "4           \\t%PDF-1.3\n",
       "             ...      \n",
       "10021       \\t%PDF-1.3\n",
       "10022    \\t%PDF-\\x07.3\n",
       "10023       \\t%PDF-1.3\n",
       "10024       \\t%PDF-1.3\n",
       "10025       \\t%PDF-1.6\n",
       "Name: header, Length: 10026, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "df = pd.read_csv(r\"Data\\PDFMalware2022.csv\")\n",
    "df[\"header\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085c28a7",
   "metadata": {},
   "source": [
    "Preparing the data.<br>\n",
    "The 'name' column is dropped as it has no significance.<br>\n",
    "The data of header column is of \"%PDF-1.(integer between 1-7)\". Only the part after the\"-\" is retained for the efficient training of model.<br>\n",
    "The data in the 'contains_text' is changed to integer type for efficient training of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3b1c096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Fine name', 'pdfsize', 'metadata size', 'pages', 'xref Length',\n",
       "       'title characters', 'isEncrypted', 'embedded files', 'images', 'text',\n",
       "       'header', 'obj', 'endobj', 'stream', 'endstream', 'xref', 'trailer',\n",
       "       'startxref', 'pageno', 'encrypt', 'ObjStm', 'JS', 'Javascript', 'AA',\n",
       "       'OpenAction', 'Acroform', 'JBIG2Decode', 'RichMedia', 'launch',\n",
       "       'EmbeddedFile', 'XFA', 'Colors', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab18f560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t%PDF-\\\\x07.3', '\\t%PDF-1.6%â', '\\t%PDF-1.3%ï', '\\t%PDF-aaa', '\\t2]', '\\ta', nan, '\\t%PDF-\\\\x00.4', '\\t%PDF-1.6\"', '\\t%PDF-\\\\\\\\\\\\\\\\x07', '\\t%PDF-1.1\"', '\\t%PDF-1.3\"', '\\t%PDF-1.5\"', '\\t%PDF-1.4\"', '\\toccured***', '\\t%PDF-1.0\"', '\\t%PDF-1.7\"', '\\t%PDF-1.4\\\\\\\\n', '\\t%PDF-1.3\\\\\\\\n', '\\t%PDF-2.4\"', '\\t%PDF-1.\"', '\\t%PDF-1.2\"', '\\t%PDF-1.0\\\\\\\\n', '\\t%PDF-aaa\"', '1', '0', '\\t/bin/sh: 1: _Cunningham_Studio.pdf: not found', '\\tError opening file /mnt/hgfs/kali_stuff/CLEAN_PDF_9000_files/Albert_Berger', \"\\t[Errno 2] No such file or directory: '/mnt/hgfs/kali_stuff/CLEAN_PDF_9000_files/Albert_Berger\", '\\t/bin/sh: 1: Syntax error: \"(\" unexpected', '\\t/bin/sh: 1: Syntax error: Unterminated quoted string', '\\tyour', '\\tError opening file /mnt/hgfs/kali_stuff/CLEAN_PDF_9000_files/Inheritances']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1096"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "o = [u for u in df['header']]\n",
    "l = [str(label) for label in df['header']]\n",
    "k = [label.split('-') for label in l]\n",
    "j = []\n",
    "p = 0\n",
    "for i in k:\n",
    "    try:\n",
    "        c = float(i[1])\n",
    "    except:\n",
    "        p+=1\n",
    "        if l[k.index(i)] not in j:\n",
    "            j.append(o[k.index(i)])\n",
    "        \n",
    "df = df.loc[~df['header'].isin(j)]\n",
    "print(j)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c699c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2(1)', '3(1)', '1(1)', '34(2)', '2(2)']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "o = [u for u in df['Javascript']]\n",
    "l = [str(label) for label in df['Javascript']]\n",
    "# k = [label.split('-') for label in l]\n",
    "j = []\n",
    "p = 0\n",
    "for i in l:\n",
    "    try:\n",
    "        c = float(i)\n",
    "    except:\n",
    "        p+=1\n",
    "        if l[l.index(i)] not in j:\n",
    "            j.append(o[l.index(i)])\n",
    "        \n",
    "df = df.loc[~df['Javascript'].isin(j)]\n",
    "print(j)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "130d3a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1(1)']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "o = [u for u in df['pageno']]\n",
    "l = [str(label) for label in df['pageno']]\n",
    "# k = [label.split('-') for label in l]\n",
    "j = []\n",
    "p = 0\n",
    "for i in l:\n",
    "    try:\n",
    "        c = float(i)\n",
    "    except:\n",
    "        p+=1\n",
    "        if l[l.index(i)] not in j:\n",
    "            j.append(o[l.index(i)])\n",
    "        \n",
    "df = df.loc[~df['pageno'].isin(j)]\n",
    "print(j)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0241b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1(1)']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "o = [u for u in df['XFA']]\n",
    "l = [str(label) for label in df['XFA']]\n",
    "# k = [label.split('-') for label in l]\n",
    "j = []\n",
    "p = 0\n",
    "for i in l:\n",
    "    try:\n",
    "        c = float(i)\n",
    "    except:\n",
    "        p+=1\n",
    "        if l[l.index(i)] not in j:\n",
    "            j.append(o[l.index(i)])\n",
    "        \n",
    "df = df.loc[~df['XFA'].isin(j)]\n",
    "print(j)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68d2483b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1(1)']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "o = [u for u in df['launch']]\n",
    "l = [str(label) for label in df['launch']]\n",
    "# k = [label.split('-') for label in l]\n",
    "j = []\n",
    "p = 0\n",
    "for i in l:\n",
    "    try:\n",
    "        c = float(i)\n",
    "    except:\n",
    "        p+=1\n",
    "        if l[l.index(i)] not in j:\n",
    "            j.append(o[l.index(i)])\n",
    "        \n",
    "df = df.loc[~df['launch'].isin(j)]\n",
    "print(j)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e47e3395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1(1)']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "o = [u for u in df['EmbeddedFile']]\n",
    "l = [str(label) for label in df['EmbeddedFile']]\n",
    "# k = [label.split('-') for label in l]\n",
    "j = []\n",
    "p = 0\n",
    "for i in l:\n",
    "    try:\n",
    "        c = float(i)\n",
    "    except:\n",
    "        p+=1\n",
    "        if l[l.index(i)] not in j:\n",
    "            j.append(o[l.index(i)])\n",
    "        \n",
    "df = df.loc[~df['EmbeddedFile'].isin(j)]\n",
    "print(j)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f0c8f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "o = [u for u in df['EmbeddedFile']]\n",
    "l = [str(label) for label in df['EmbeddedFile']]\n",
    "# k = [label.split('-') for label in l]\n",
    "j = []\n",
    "p = 0\n",
    "for i in l:\n",
    "    try:\n",
    "        c = float(i)\n",
    "    except:\n",
    "        p+=1\n",
    "        if l[l.index(i)] not in j:\n",
    "            j.append(o[l.index(i)])\n",
    "        \n",
    "df = df.loc[~df['EmbeddedFile'].isin(j)]\n",
    "print(j)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fc5729c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fine name',\n",
       " 'pdfsize',\n",
       " 'metadata size',\n",
       " 'pages',\n",
       " 'xref Length',\n",
       " 'title characters',\n",
       " 'isEncrypted',\n",
       " 'embedded files',\n",
       " 'images',\n",
       " 'text']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "d = {\n",
    "            'header': '-1',\n",
    "            'obj': -1,\n",
    "            'endobj': -1,\n",
    "            'stream': -1,\n",
    "            'endstream': -1,\n",
    "            'xref': -1,\n",
    "            'trailer': -1,\n",
    "            'startxref': -1,\n",
    "            'pageno': -1,\n",
    "            'encrypt': -1,\n",
    "            'ObjStm': -1,\n",
    "            'JS': -1,\n",
    "            'Javascript': -1,\n",
    "            'AA': -1,\n",
    "            'OpenAction': -1,\n",
    "            'Acroform': -1,\n",
    "            'JBIG2Decode': -1,\n",
    "            'RichMedia': -1,\n",
    "            'launch': -1,\n",
    "            'EmbeddedFile': -1,\n",
    "            'XFA': -1,\n",
    "            'Colors': -1,\n",
    "            'Class':-1\n",
    "        }\n",
    "col = []\n",
    "for i in df.columns:\n",
    "    if i not in d.keys():\n",
    "        col.append(i)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "599b8c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agraw\\AppData\\Local\\Temp\\ipykernel_30612\\1021837581.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Class']=df['Class'].replace(['Benign','Malicious'],[0,1])\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns = col)\n",
    "df[\"header\"]=[label.split('-')[1] for label in df['header']]\n",
    "# df['contains_text']=df['contains_text'].replace([\"Yes\",\"No\"],[1,0])\n",
    "df['Class']=df['Class'].replace(['Benign','Malicious'],[0,1])\n",
    "#df=df.drop(columns=['pdf_size', 'metadata_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b3f5f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header</th>\n",
       "      <th>obj</th>\n",
       "      <th>endobj</th>\n",
       "      <th>stream</th>\n",
       "      <th>endstream</th>\n",
       "      <th>xref</th>\n",
       "      <th>trailer</th>\n",
       "      <th>startxref</th>\n",
       "      <th>pageno</th>\n",
       "      <th>encrypt</th>\n",
       "      <th>...</th>\n",
       "      <th>AA</th>\n",
       "      <th>OpenAction</th>\n",
       "      <th>Acroform</th>\n",
       "      <th>JBIG2Decode</th>\n",
       "      <th>RichMedia</th>\n",
       "      <th>launch</th>\n",
       "      <th>EmbeddedFile</th>\n",
       "      <th>XFA</th>\n",
       "      <th>Colors</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.6</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.3</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  header obj endobj  stream endstream xref  trailer startxref pageno  encrypt  \\\n",
       "0    1.3  10     10     3.0         3    1      1.0         1      1      0.0   \n",
       "1    1.6  19     19     9.0         9    1      1.0         1      1      0.0   \n",
       "2    1.3  12     12     3.0         3    1      1.0         1      2      0.0   \n",
       "3    1.3  14     14     2.0         2    1      1.0         1      1      0.0   \n",
       "4    1.3  15     15     4.0         4    1      1.0         1      3      0.0   \n",
       "\n",
       "   ...  AA OpenAction Acroform JBIG2Decode RichMedia launch EmbeddedFile XFA  \\\n",
       "0  ...   0          1        0           0         0      0            0   0   \n",
       "1  ...   0          0        1           0         0      0            8   1   \n",
       "2  ...   0          1        0           0         0      0            0   0   \n",
       "3  ...   0          1        1           0         0      0            0   0   \n",
       "4  ...   0          1        0           0         0      0            0   0   \n",
       "\n",
       "  Colors Class  \n",
       "0    0.0     1  \n",
       "1    0.0     1  \n",
       "2    0.0     1  \n",
       "3    0.0     1  \n",
       "4    0.0     1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d41f130",
   "metadata": {},
   "source": [
    "Spliting the dataset into Training and Testing Data.<br>\n",
    "Creating a function for scalling and oversampling.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0b63d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agraw\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "train, test = np.split(df.sample(frac=1), [int(0.6*len(df))])\n",
    "def scale_dataset(dataframe, oversample=False):\n",
    "    X = dataframe[dataframe.columns[0:-1]].values\n",
    "    y = dataframe[dataframe.columns[-1]].values\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    # X = scaler.fit_transform(X)\n",
    "    # if oversample:\n",
    "   \n",
    "    #    ros = RandomOverSampler()\n",
    "    #    X, y = ros.fit_resample(X, y)\n",
    "\n",
    "    data = np.hstack((X, np.reshape(y, (-1, 1))))\n",
    "\n",
    "    return data, X, y\n",
    "train, X_train, y_train = scale_dataset(train, oversample=True)\n",
    "test, X_test, y_test = scale_dataset(test, oversample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "973d5542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da9ed983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1774\n",
      "           1       0.99      0.98      0.99      1730\n",
      "\n",
      "    accuracy                           0.99      3504\n",
      "   macro avg       0.99      0.99      0.99      3504\n",
      "weighted avg       0.99      0.99      0.99      3504\n",
      "\n",
      "0.9894406392694064\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)  # You can adjust the number of estimators as needed\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(accuracy_score(y_test, rf_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbf70356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1774\n",
      "           1       0.99      0.99      0.99      1730\n",
      "\n",
      "    accuracy                           0.99      3504\n",
      "   macro avg       0.99      0.99      0.99      3504\n",
      "weighted avg       0.99      0.99      0.99      3504\n",
      "\n",
      "0.9897260273972602\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "rf_model = RandomForestClassifier(n_estimators=  400, min_samples_split = 2, min_samples_leaf = 1, max_features = 'log2', max_depth = 40, bootstrap = True)  # You can adjust the number of estimators as needed\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(accuracy_score(y_test, rf_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4212a4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9882990867579908\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "#feature_importance = model.feature_importances_\n",
    "#print(\"Feature Importance:\", feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3e473b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models/random_forest_model.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(rf_model, 'saved_models/random_forest_model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed038d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.metrics import classification_report, accuracy_score\n",
    "# from scipy.stats import randint\n",
    "\n",
    "# # Assuming X_train, y_train, X_test, y_test are already defined\n",
    "\n",
    "# # Define the parameter grid for RandomizedSearchCV\n",
    "# param_dist = {\n",
    "#     'n_estimators': np.arange(100, 1000, 100),  # Number of trees in the forest\n",
    "#     'max_depth': [None, 10, 20, 30, 40, 50],  # Maximum depth of the tree\n",
    "#     'min_samples_split': np.arange(2, 11),  # Minimum number of samples required to split an internal node\n",
    "#     'min_samples_leaf': np.arange(1, 5),  # Minimum number of samples required to be at a leaf node\n",
    "#     'max_features': ['sqrt', 'log2'],  # Number of features to consider when looking for the best split\n",
    "#     'bootstrap': [True, False]  # Whether bootstrap samples are used when building trees\n",
    "# }\n",
    "\n",
    "# # Initialize the RandomForestClassifier\n",
    "# rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# # Perform RandomizedSearchCV with 5-fold cross-validation\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     rf_model, \n",
    "#     param_distributions=param_dist,\n",
    "#     n_iter=50,  # Number of parameter settings that are sampled\n",
    "#     scoring='accuracy',  # Scoring metric\n",
    "#     cv=5,  # 5-fold cross-validation\n",
    "#     verbose=2,  # For detailed output\n",
    "#     random_state=42,  # For reproducibility\n",
    "#     n_jobs=-1  # Use all available cores\n",
    "# )\n",
    "\n",
    "# # Fit the model with the hyperparameter tuning\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# # Print the best parameters found by RandomizedSearchCV\n",
    "# print(\"Best Parameters found:\", random_search.best_params_)\n",
    "\n",
    "# # Predict using the best model from RandomizedSearchCV\n",
    "# best_rf_model = random_search.best_estimator_\n",
    "# y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# # Output classification report and accuracy\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_test, y_pred_rf))\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0fac0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a06cde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
